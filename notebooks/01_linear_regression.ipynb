{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4041da",
   "metadata": {},
   "source": [
    "# Linear Regression: House Price Prediction\n",
    "\n",
    "## Problem Overview\n",
    "\n",
    "Linear regression is one of the fundamental algorithms in machine learning for supervised learning tasks. This notebook demonstrates end-to-end implementation of linear regression for predicting house prices based on various features.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the mathematical foundation of linear regression\n",
    "- Implement data preprocessing and feature engineering\n",
    "- Train and evaluate linear regression models\n",
    "- Visualize model performance and residual analysis\n",
    "- Handle real-world data challenges\n",
    "\n",
    "### Mathematical Foundation\n",
    "\n",
    "Linear regression assumes a linear relationship between input features and target variable:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n + \\epsilon$$\n",
    "\n",
    "Where:\n",
    "- $y$ is the target variable (house price)\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_i$ are the coefficients for features $x_i$\n",
    "- $\\epsilon$ is the error term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f31a5",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We start by importing all necessary libraries for data manipulation, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and numerical computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, Optional, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.datasets import make_regression, fetch_california_housing\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeccbd12",
   "metadata": {},
   "source": [
    "## 2. Data Generation and Loading\n",
    "\n",
    "We'll work with both synthetic and real datasets to understand different aspects of linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb13633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_house_price_data(n_samples: int = 1000, noise_level: float = 0.1) -> pd.DataFrame:\n",
    "    \"\"\"Generate synthetic house price dataset with realistic features.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples to generate\n",
    "        noise_level: Amount of noise to add to the target variable\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with house features and prices\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate realistic house features\n",
    "    house_size = np.random.normal(2000, 500, n_samples)  # Square feet\n",
    "    house_size = np.clip(house_size, 500, 5000)  # Reasonable bounds\n",
    "    \n",
    "    bedrooms = np.random.poisson(3, n_samples) + 1  # 1-7 bedrooms typically\n",
    "    bedrooms = np.clip(bedrooms, 1, 7)\n",
    "    \n",
    "    bathrooms = np.random.normal(2.5, 0.8, n_samples)  # 1-5 bathrooms\n",
    "    bathrooms = np.clip(bathrooms, 1, 5)\n",
    "    \n",
    "    age = np.random.exponential(15, n_samples)  # House age in years\n",
    "    age = np.clip(age, 0, 100)\n",
    "    \n",
    "    # Distance to city center (km)\n",
    "    distance_to_center = np.random.gamma(2, 5, n_samples)\n",
    "    distance_to_center = np.clip(distance_to_center, 1, 50)\n",
    "    \n",
    "    # School rating (1-10)\n",
    "    school_rating = np.random.beta(2, 2, n_samples) * 10\n",
    "    \n",
    "    # Generate price based on realistic relationships\n",
    "    base_price = (\n",
    "        100 * house_size +  # $100 per sq ft\n",
    "        15000 * bedrooms +   # $15k per bedroom\n",
    "        20000 * bathrooms +  # $20k per bathroom\n",
    "        -2000 * age +        # Depreciation\n",
    "        -1000 * distance_to_center +  # Location premium\n",
    "        5000 * school_rating +  # School district premium\n",
    "        100000  # Base price\n",
    "    )\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, noise_level * np.mean(base_price), n_samples)\n",
    "    price = base_price + noise\n",
    "    \n",
    "    # Ensure positive prices\n",
    "    price = np.maximum(price, 50000)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'house_size_sqft': house_size,\n",
    "        'bedrooms': bedrooms,\n",
    "        'bathrooms': bathrooms,\n",
    "        'age_years': age,\n",
    "        'distance_to_center_km': distance_to_center,\n",
    "        'school_rating': school_rating,\n",
    "        'price': price\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate synthetic dataset\n",
    "df_synthetic = generate_house_price_data(n_samples=1000)\n",
    "print(f\"Generated synthetic dataset with {len(df_synthetic)} samples\")\n",
    "print(f\"Features: {list(df_synthetic.columns[:-1])}\")\n",
    "print(f\"Target: {df_synthetic.columns[-1]}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nDataset Statistics:\")\n",
    "df_synthetic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1073b5",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Understanding our data is crucial before building models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Perform comprehensive exploratory data analysis.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "    \"\"\"\n",
    "    print(\"=== EXPLORATORY DATA ANALYSIS ===\")\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Target variable distribution\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Price distribution\n",
    "    axes[0, 0].hist(df['price'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_title('Price Distribution')\n",
    "    axes[0, 0].set_xlabel('Price ($)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Log price distribution (often more normal)\n",
    "    axes[0, 1].hist(np.log(df['price']), bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[0, 1].set_title('Log Price Distribution')\n",
    "    axes[0, 1].set_xlabel('Log Price')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Price vs house size (most important feature)\n",
    "    axes[1, 0].scatter(df['house_size_sqft'], df['price'], alpha=0.6, color='coral')\n",
    "    axes[1, 0].set_title('Price vs House Size')\n",
    "    axes[1, 0].set_xlabel('House Size (sq ft)')\n",
    "    axes[1, 0].set_ylabel('Price ($)')\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    corr_matrix = df.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Feature Correlation Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print correlation with target\n",
    "    print(\"\\nCorrelation with price:\")\n",
    "    price_corr = df.corr()['price'].sort_values(ascending=False)\n",
    "    for feature, corr in price_corr.items():\n",
    "        if feature != 'price':\n",
    "            print(f\"{feature}: {corr:.3f}\")\n",
    "\n",
    "# Perform EDA\n",
    "perform_eda(df_synthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52dd3dd",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Prepare the data for machine learning by handling missing values, scaling features, and splitting into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80511aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame, target_col: str = 'price', \n",
    "                   test_size: float = 0.2, scale_features: bool = True) -> Tuple:\n",
    "    \"\"\"Preprocess data for machine learning.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        target_col: Name of target column\n",
    "        test_size: Proportion for test set\n",
    "        scale_features: Whether to standardize features\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (X_train, X_test, y_train, y_test, scaler, feature_names)\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features if requested\n",
    "    scaler = None\n",
    "    if scale_features:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler, feature_names\n",
    "\n",
    "# Preprocess the data\n",
    "X_train, X_test, y_train, y_test, scaler, feature_names = preprocess_data(df_synthetic)\n",
    "\n",
    "print(\"\\nFeature scaling statistics (training set):\")\n",
    "if scaler is not None:\n",
    "    print(f\"Feature means: {scaler.mean_}\")\n",
    "    print(f\"Feature std: {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad7f2cc",
   "metadata": {},
   "source": [
    "## 5. Model Implementation and Training\n",
    "\n",
    "Implement different variants of linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_models(X_train: np.ndarray, y_train: np.ndarray) -> dict:\n",
    "    \"\"\"Train multiple linear regression variants.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training targets\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of trained models\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Lasso Regression': Lasso(alpha=1.0),\n",
    "    }\n",
    "    \n",
    "    trained_models = {}\n",
    "    \n",
    "    print(\"Training models...\")\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[name] = model\n",
    "        \n",
    "        # Print model coefficients\n",
    "        if hasattr(model, 'coef_'):\n",
    "            print(f\"Intercept: {model.intercept_:.2f}\")\n",
    "            print(f\"Coefficients: {model.coef_}\")\n",
    "            \n",
    "    return trained_models\n",
    "\n",
    "# Train models\n",
    "models = train_linear_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827dc5c",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Evaluate model performance using multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749591d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_models(models: dict, X_train: np.ndarray, X_test: np.ndarray,\n",
    "                             y_train: np.ndarray, y_test: np.ndarray) -> pd.DataFrame:\n",
    "    \"\"\"Evaluate regression models comprehensively.\n",
    "    \n",
    "    Args:\n",
    "        models: Dictionary of trained models\n",
    "        X_train, X_test: Training and test features\n",
    "        y_train, y_test: Training and test targets\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with evaluation metrics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Make predictions\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_r2 = r2_score(y_train, train_pred)\n",
    "        test_r2 = r2_score(y_test, test_pred)\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train, train_pred)\n",
    "        test_mse = mean_squared_error(y_test, test_pred)\n",
    "        \n",
    "        train_mae = mean_absolute_error(y_train, train_pred)\n",
    "        test_mae = mean_absolute_error(y_test, test_pred)\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Train R²': train_r2,\n",
    "            'Test R²': test_r2,\n",
    "            'Train RMSE': np.sqrt(train_mse),\n",
    "            'Test RMSE': np.sqrt(test_mse),\n",
    "            'Train MAE': train_mae,\n",
    "            'Test MAE': test_mae,\n",
    "            'CV R² Mean': cv_scores.mean(),\n",
    "            'CV R² Std': cv_scores.std()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Evaluate models\n",
    "evaluation_results = evaluate_regression_models(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(evaluation_results.round(4))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = evaluation_results.loc[evaluation_results['Test R²'].idxmax(), 'Model']\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nBest performing model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc37f2",
   "metadata": {},
   "source": [
    "## 7. Model Interpretation and Feature Importance\n",
    "\n",
    "Understand which features are most important for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaedcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, feature_names: List[str]) -> None:\n",
    "    \"\"\"Analyze and visualize feature importance.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained linear model\n",
    "        feature_names: Names of features\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'coef_'):\n",
    "        coefficients = model.coef_\n",
    "        \n",
    "        # Create feature importance DataFrame\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': coefficients,\n",
    "            'Abs_Coefficient': np.abs(coefficients)\n",
    "        }).sort_values('Abs_Coefficient', ascending=False)\n",
    "        \n",
    "        print(\"Feature Importance (by coefficient magnitude):\")\n",
    "        print(importance_df)\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Coefficient values\n",
    "        plt.subplot(2, 1, 1)\n",
    "        colors = ['red' if coef < 0 else 'green' for coef in importance_df['Coefficient']]\n",
    "        plt.barh(importance_df['Feature'], importance_df['Coefficient'], color=colors, alpha=0.7)\n",
    "        plt.title('Feature Coefficients (Positive = Increases Price, Negative = Decreases Price)')\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Absolute coefficient values\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.barh(importance_df['Feature'], importance_df['Abs_Coefficient'], \n",
    "                color='skyblue', alpha=0.7)\n",
    "        plt.title('Feature Importance (Absolute Coefficient Values)')\n",
    "        plt.xlabel('Absolute Coefficient Value')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "    else:\n",
    "        print(\"Model does not have coefficients to analyze.\")\n",
    "        return None\n",
    "\n",
    "# Analyze feature importance\n",
    "feature_importance = analyze_feature_importance(best_model, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ba55d",
   "metadata": {},
   "source": [
    "## 8. Residual Analysis\n",
    "\n",
    "Analyze model residuals to check assumptions and identify potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_residual_analysis(model, X_test: np.ndarray, y_test: np.ndarray) -> None:\n",
    "    \"\"\"Perform comprehensive residual analysis.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test targets\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Predicted vs Actual\n",
    "    axes[0, 0].scatter(y_test, y_pred, alpha=0.6, color='blue')\n",
    "    axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                   'r--', lw=2, label='Perfect Prediction')\n",
    "    axes[0, 0].set_xlabel('Actual Values')\n",
    "    axes[0, 0].set_ylabel('Predicted Values')\n",
    "    axes[0, 0].set_title('Predicted vs Actual Values')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Residuals vs Predicted\n",
    "    axes[0, 1].scatter(y_pred, residuals, alpha=0.6, color='green')\n",
    "    axes[0, 1].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0, 1].set_xlabel('Predicted Values')\n",
    "    axes[0, 1].set_ylabel('Residuals')\n",
    "    axes[0, 1].set_title('Residuals vs Predicted Values')\n",
    "    \n",
    "    # 3. Residual distribution\n",
    "    axes[1, 0].hist(residuals, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Residuals')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Residual Distribution')\n",
    "    \n",
    "    # 4. Q-Q plot for normality check\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[1, 1])\n",
    "    axes[1, 1].set_title('Q-Q Plot (Normality Check)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical tests\n",
    "    print(\"Residual Analysis Summary:\")\n",
    "    print(f\"Mean residual: {np.mean(residuals):.6f} (should be close to 0)\")\n",
    "    print(f\"Std residual: {np.std(residuals):.2f}\")\n",
    "    \n",
    "    # Shapiro-Wilk test for normality\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(residuals[:5000])  # Limit sample size\n",
    "    print(f\"Shapiro-Wilk test p-value: {shapiro_p:.6f}\")\n",
    "    if shapiro_p > 0.05:\n",
    "        print(\"✓ Residuals appear to be normally distributed\")\n",
    "    else:\n",
    "        print(\"✗ Residuals may not be normally distributed\")\n",
    "    \n",
    "    # Durbin-Watson test for autocorrelation\n",
    "    from statsmodels.stats.diagnostic import durbin_watson\n",
    "    dw_stat = durbin_watson(residuals)\n",
    "    print(f\"Durbin-Watson statistic: {dw_stat:.3f} (2.0 indicates no autocorrelation)\")\n",
    "\n",
    "# Perform residual analysis\n",
    "perform_residual_analysis(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201d39a",
   "metadata": {},
   "source": [
    "## 9. Polynomial Regression Extension\n",
    "\n",
    "Explore polynomial features to capture non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b63b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_polynomial_regression(X_train: np.ndarray, X_test: np.ndarray, \n",
    "                              y_train: np.ndarray, y_test: np.ndarray,\n",
    "                              degrees: List[int] = [2, 3]) -> dict:\n",
    "    \"\"\"Train polynomial regression models.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test: Training and test features\n",
    "        y_train, y_test: Training and test targets\n",
    "        degrees: List of polynomial degrees to try\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with polynomial models and results\n",
    "    \"\"\"\n",
    "    poly_results = []\n",
    "    poly_models = {}\n",
    "    \n",
    "    for degree in degrees:\n",
    "        print(f\"\\nTraining Polynomial Regression (degree {degree})...\")\n",
    "        \n",
    "        # Create polynomial features\n",
    "        poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        X_train_poly = poly_features.fit_transform(X_train)\n",
    "        X_test_poly = poly_features.transform(X_test)\n",
    "        \n",
    "        print(f\"Original features: {X_train.shape[1]}\")\n",
    "        print(f\"Polynomial features: {X_train_poly.shape[1]}\")\n",
    "        \n",
    "        # Train model with regularization to prevent overfitting\n",
    "        model = Ridge(alpha=1.0)  # Use Ridge to handle high-dimensional polynomial features\n",
    "        model.fit(X_train_poly, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        train_pred = model.predict(X_train_poly)\n",
    "        test_pred = model.predict(X_test_poly)\n",
    "        \n",
    "        train_r2 = r2_score(y_train, train_pred)\n",
    "        test_r2 = r2_score(y_test, test_pred)\n",
    "        \n",
    "        poly_results.append({\n",
    "            'Degree': degree,\n",
    "            'Train R²': train_r2,\n",
    "            'Test R²': test_r2,\n",
    "            'Train RMSE': np.sqrt(mean_squared_error(y_train, train_pred)),\n",
    "            'Test RMSE': np.sqrt(mean_squared_error(y_test, test_pred)),\n",
    "            'Features': X_train_poly.shape[1]\n",
    "        })\n",
    "        \n",
    "        poly_models[f'Poly_{degree}'] = {\n",
    "            'model': model,\n",
    "            'poly_features': poly_features\n",
    "        }\n",
    "    \n",
    "    # Display results\n",
    "    poly_df = pd.DataFrame(poly_results)\n",
    "    print(\"\\nPolynomial Regression Results:\")\n",
    "    print(poly_df.round(4))\n",
    "    \n",
    "    # Plot complexity vs performance\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(poly_df['Degree'], poly_df['Train R²'], 'o-', label='Training R²', color='blue')\n",
    "    plt.plot(poly_df['Degree'], poly_df['Test R²'], 'o-', label='Test R²', color='red')\n",
    "    plt.xlabel('Polynomial Degree')\n",
    "    plt.ylabel('R² Score')\n",
    "    plt.title('Model Performance vs Polynomial Degree')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(poly_df['Features'], poly_df['Test R²'], 'o-', color='green')\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('Test R² Score')\n",
    "    plt.title('Test Performance vs Model Complexity')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return poly_models, poly_df\n",
    "\n",
    "# Train polynomial regression models\n",
    "poly_models, poly_results_df = train_polynomial_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b1850",
   "metadata": {},
   "source": [
    "## 10. Model Comparison and Selection\n",
    "\n",
    "Compare all models and select the best one based on multiple criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ab92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_models() -> None:\n",
    "    \"\"\"Compare all trained models and provide recommendations.\"\"\"\n",
    "    print(\"=== MODEL COMPARISON SUMMARY ===\")\n",
    "    \n",
    "    # Combine linear and polynomial results\n",
    "    print(\"\\n1. Linear Models:\")\n",
    "    print(evaluation_results[['Model', 'Test R²', 'Test RMSE', 'CV R² Mean']].round(4))\n",
    "    \n",
    "    print(\"\\n2. Polynomial Models:\")\n",
    "    print(poly_results_df[['Degree', 'Test R²', 'Test RMSE', 'Features']].round(4))\n",
    "    \n",
    "    # Model selection criteria\n",
    "    print(\"\\n=== MODEL SELECTION CRITERIA ===\")\n",
    "    \n",
    "    # Best linear model\n",
    "    best_linear_idx = evaluation_results['Test R²'].idxmax()\n",
    "    best_linear = evaluation_results.iloc[best_linear_idx]\n",
    "    print(f\"\\nBest Linear Model: {best_linear['Model']}\")\n",
    "    print(f\"  - Test R²: {best_linear['Test R²']:.4f}\")\n",
    "    print(f\"  - Test RMSE: {best_linear['Test RMSE']:.2f}\")\n",
    "    print(f\"  - CV R² Mean: {best_linear['CV R² Mean']:.4f}\")\n",
    "    \n",
    "    # Best polynomial model\n",
    "    best_poly_idx = poly_results_df['Test R²'].idxmax()\n",
    "    best_poly = poly_results_df.iloc[best_poly_idx]\n",
    "    print(f\"\\nBest Polynomial Model: Degree {best_poly['Degree']}\")\n",
    "    print(f\"  - Test R²: {best_poly['Test R²']:.4f}\")\n",
    "    print(f\"  - Test RMSE: {best_poly['Test RMSE']:.2f}\")\n",
    "    print(f\"  - Features: {best_poly['Features']}\")\n",
    "    \n",
    "    # Overall recommendation\n",
    "    print(\"\\n=== RECOMMENDATION ===\")\n",
    "    if best_linear['Test R²'] > best_poly['Test R²'] - 0.01:  # Small tolerance\n",
    "        print(f\"Recommended Model: {best_linear['Model']}\")\n",
    "        print(\"Reason: Simpler model with comparable performance (Occam's Razor)\")\n",
    "    else:\n",
    "        print(f\"Recommended Model: Polynomial Degree {best_poly['Degree']}\")\n",
    "        print(\"Reason: Significantly better performance justifies complexity\")\n",
    "    \n",
    "    # Visualization of all models\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    all_models = []\n",
    "    all_r2 = []\n",
    "    all_rmse = []\n",
    "    \n",
    "    # Add linear models\n",
    "    for _, row in evaluation_results.iterrows():\n",
    "        all_models.append(row['Model'])\n",
    "        all_r2.append(row['Test R²'])\n",
    "        all_rmse.append(row['Test RMSE'])\n",
    "    \n",
    "    # Add polynomial models\n",
    "    for _, row in poly_results_df.iterrows():\n",
    "        all_models.append(f\"Poly Deg {row['Degree']}\")\n",
    "        all_r2.append(row['Test R²'])\n",
    "        all_rmse.append(row['Test RMSE'])\n",
    "    \n",
    "    # Plot R² scores\n",
    "    plt.subplot(1, 2, 1)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(all_models)))\n",
    "    bars = plt.bar(range(len(all_models)), all_r2, color=colors, alpha=0.7)\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Test R² Score')\n",
    "    plt.title('Model Comparison: R² Scores')\n",
    "    plt.xticks(range(len(all_models)), all_models, rotation=45, ha='right')\n",
    "    \n",
    "    # Highlight best model\n",
    "    best_idx = np.argmax(all_r2)\n",
    "    bars[best_idx].set_color('red')\n",
    "    bars[best_idx].set_alpha(1.0)\n",
    "    \n",
    "    # Plot RMSE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    bars = plt.bar(range(len(all_models)), all_rmse, color=colors, alpha=0.7)\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Test RMSE')\n",
    "    plt.title('Model Comparison: RMSE (Lower is Better)')\n",
    "    plt.xticks(range(len(all_models)), all_models, rotation=45, ha='right')\n",
    "    \n",
    "    # Highlight best model (lowest RMSE)\n",
    "    best_rmse_idx = np.argmin(all_rmse)\n",
    "    bars[best_rmse_idx].set_color('red')\n",
    "    bars[best_rmse_idx].set_alpha(1.0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compare all models\n",
    "compare_all_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c4045",
   "metadata": {},
   "source": [
    "## 11. Real-World Application: California Housing Dataset\n",
    "\n",
    "Apply our best model to a real dataset to validate its effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_real_data() -> None:\n",
    "    \"\"\"Apply the best model to real California housing data.\"\"\"\n",
    "    print(\"=== REAL-WORLD VALIDATION ===\")\n",
    "    \n",
    "    # Load California housing dataset\n",
    "    california_data = fetch_california_housing()\n",
    "    X_real = california_data.data\n",
    "    y_real = california_data.target * 100000  # Convert to actual dollar values\n",
    "    feature_names_real = california_data.feature_names\n",
    "    \n",
    "    print(f\"California Housing Dataset:\")\n",
    "    print(f\"  - Samples: {X_real.shape[0]}\")\n",
    "    print(f\"  - Features: {X_real.shape[1]}\")\n",
    "    print(f\"  - Features: {feature_names_real}\")\n",
    "    print(f\"  - Target: Median house value ($)\")\n",
    "    \n",
    "    # Split and scale data\n",
    "    X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "        X_real, y_real, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler_real = StandardScaler()\n",
    "    X_train_real_scaled = scaler_real.fit_transform(X_train_real)\n",
    "    X_test_real_scaled = scaler_real.transform(X_test_real)\n",
    "    \n",
    "    # Train our best model on real data\n",
    "    best_model_real = LinearRegression()  # Use the model type that performed best\n",
    "    best_model_real.fit(X_train_real_scaled, y_train_real)\n",
    "    \n",
    "    # Evaluate on real data\n",
    "    y_pred_real = best_model_real.predict(X_test_real_scaled)\n",
    "    \n",
    "    r2_real = r2_score(y_test_real, y_pred_real)\n",
    "    rmse_real = np.sqrt(mean_squared_error(y_test_real, y_pred_real))\n",
    "    mae_real = mean_absolute_error(y_test_real, y_pred_real)\n",
    "    \n",
    "    print(f\"\\nReal Data Results:\")\n",
    "    print(f\"  - R² Score: {r2_real:.4f}\")\n",
    "    print(f\"  - RMSE: ${rmse_real:,.2f}\")\n",
    "    print(f\"  - MAE: ${mae_real:,.2f}\")\n",
    "    \n",
    "    # Feature importance on real data\n",
    "    importance_real = pd.DataFrame({\n",
    "        'Feature': feature_names_real,\n",
    "        'Coefficient': best_model_real.coef_,\n",
    "        'Abs_Coefficient': np.abs(best_model_real.coef_)\n",
    "    }).sort_values('Abs_Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance (Real Data):\")\n",
    "    print(importance_real)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Predicted vs Actual\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(y_test_real, y_pred_real, alpha=0.5, color='blue')\n",
    "    plt.plot([y_test_real.min(), y_test_real.max()], \n",
    "             [y_test_real.min(), y_test_real.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Price ($)')\n",
    "    plt.ylabel('Predicted Price ($)')\n",
    "    plt.title(f'Real Data: Predicted vs Actual (R² = {r2_real:.3f})')\n",
    "    \n",
    "    # Residuals\n",
    "    residuals_real = y_test_real - y_pred_real\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.scatter(y_pred_real, residuals_real, alpha=0.5, color='green')\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.xlabel('Predicted Price ($)')\n",
    "    plt.ylabel('Residuals ($)')\n",
    "    plt.title('Residuals vs Predicted')\n",
    "    \n",
    "    # Feature importance\n",
    "    plt.subplot(2, 2, 3)\n",
    "    colors = ['red' if coef < 0 else 'green' for coef in importance_real['Coefficient']]\n",
    "    plt.barh(importance_real['Feature'], importance_real['Coefficient'], \n",
    "             color=colors, alpha=0.7)\n",
    "    plt.title('Feature Coefficients (Real Data)')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Error distribution\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(residuals_real, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "    plt.xlabel('Residuals ($)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Residual Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Apply to real data\n",
    "apply_to_real_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c52fe",
   "metadata": {},
   "source": [
    "## 12. Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Linear Regression Fundamentals**: We implemented linear regression from scratch and using scikit-learn, understanding the mathematical foundation and assumptions.\n",
    "\n",
    "2. **Data Preprocessing**: Proper data preprocessing including scaling, splitting, and handling different data types is crucial for model performance.\n",
    "\n",
    "3. **Model Variants**: We explored different variants:\n",
    "   - **Linear Regression**: Basic least squares solution\n",
    "   - **Ridge Regression**: L2 regularization to prevent overfitting\n",
    "   - **Lasso Regression**: L1 regularization for feature selection\n",
    "   - **Polynomial Regression**: Capturing non-linear relationships\n",
    "\n",
    "4. **Evaluation Metrics**: Multiple metrics provide different insights:\n",
    "   - **R²**: Proportion of variance explained\n",
    "   - **RMSE**: Root mean squared error in original units\n",
    "   - **MAE**: Mean absolute error, robust to outliers\n",
    "\n",
    "5. **Model Interpretation**: Linear models are highly interpretable through coefficient analysis.\n",
    "\n",
    "6. **Residual Analysis**: Checking model assumptions through residual patterns.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Always scale features** when using regularized models\n",
    "2. **Use cross-validation** for robust performance estimation\n",
    "3. **Analyze residuals** to validate model assumptions\n",
    "4. **Consider regularization** to prevent overfitting\n",
    "5. **Test on real data** to validate model generalization\n",
    "\n",
    "### When to Use Linear Regression\n",
    "\n",
    "✅ **Good for:**\n",
    "- Linear relationships between features and target\n",
    "- Interpretability is important\n",
    "- Baseline model for comparison\n",
    "- Small to medium datasets\n",
    "- When you need to understand feature importance\n",
    "\n",
    "❌ **Not ideal for:**\n",
    "- Highly non-linear relationships\n",
    "- Very high-dimensional data without regularization\n",
    "- When interpretability is not needed and accuracy is paramount\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Explore **ensemble methods** like Random Forest\n",
    "2. Try **non-linear models** like SVM or Neural Networks\n",
    "3. Implement **feature engineering** techniques\n",
    "4. Learn about **advanced regularization** methods\n",
    "5. Study **time series** regression for temporal data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66c519",
   "metadata": {},
   "source": [
    "## 13. Practice Exercises\n",
    "\n",
    "### Exercise 1: Feature Engineering\n",
    "Create new features from existing ones (e.g., price per square foot, age categories) and see how they affect model performance.\n",
    "\n",
    "### Exercise 2: Outlier Detection\n",
    "Implement outlier detection and removal techniques and analyze their impact on model performance.\n",
    "\n",
    "### Exercise 3: Different Datasets\n",
    "Apply the same pipeline to other regression datasets (e.g., Boston housing, automobile prices).\n",
    "\n",
    "### Exercise 4: Hyperparameter Tuning\n",
    "Use GridSearchCV to find optimal regularization parameters for Ridge and Lasso regression.\n",
    "\n",
    "### Exercise 5: Advanced Metrics\n",
    "Implement additional evaluation metrics like MAPE (Mean Absolute Percentage Error) and analyze when each metric is most appropriate."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
