{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0de9e60",
   "metadata": {},
   "source": [
    "# Chapter 11: Naive Bayes Classification\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this chapter, you will learn:\n",
    "- **Mathematical foundations** of Bayes' theorem and conditional independence\n",
    "- **Gaussian, Multinomial, and Bernoulli** Naive Bayes variants\n",
    "- **Text classification** and sentiment analysis applications\n",
    "- **Implementation** from scratch and with Scikit-learn\n",
    "- **Handling of categorical and continuous features**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Naive Bayes is a probabilistic classifier based on Bayes' theorem with strong independence assumptions between features. Despite its simplicity, it performs remarkably well in many real-world applications.\n",
    "\n",
    "**Mathematical Foundation**: Naive Bayes applies Bayes' theorem with the naive assumption of conditional independence between features given the class label.\n",
    "\n",
    "## Mathematical Theory\n",
    "\n",
    "### Bayes' Theorem\n",
    "\n",
    "The posterior probability is calculated as:\n",
    "\n",
    "$$P(y|x_1, ..., x_n) = \\frac{P(y) \\prod_{i=1}^{n} P(x_i|y)}{P(x_1, ..., x_n)}$$\n",
    "\n",
    "Where:\n",
    "- $P(y|x_1, ..., x_n)$ is the posterior probability\n",
    "- $P(y)$ is the prior probability of class $y$\n",
    "- $P(x_i|y)$ is the likelihood of feature $x_i$ given class $y$\n",
    "\n",
    "**Citation**: Bayesian inference and probabilistic models are extensively covered in pattern recognition literature."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
